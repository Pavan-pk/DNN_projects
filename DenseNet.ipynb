{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavan-pk/deep_nn/blob/master/DenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-6v0tqqppRD",
        "colab_type": "code",
        "outputId": "d6efd041-b128-4aba-95c0-7a309973ee7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import plot_model\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "data_agumentation = True\n",
        "\n",
        "num_classes = 10\n",
        "num_dense_block = 3\n",
        "use_max_pool = False\n",
        "\n",
        "growth_rate = 12\n",
        "depth = 100\n",
        "num_bottleneck_layers = (depth - 4) // (2 * num_dense_blocks)\n",
        "\n",
        "num_filters_bef_dense_block = 2 * growth_rate\n",
        "compression_factor = 0.5\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "x_train = x_train.astype('float')/255\n",
        "x_test = x_test.astype('float')/255\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "inputs = Input(shape = input_shape)\n",
        "x = BatchNormalization()(inputs)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(num_filters_bef_dense_block,\n",
        "           kernel_size=3,\n",
        "           padding='same',\n",
        "           kernel_initializer='he_normal')(x)\n",
        "x = concatenate([inputs, x])\n",
        "\n",
        "for i in range(num_dense_block):\n",
        "    for j in range(num_bottleneck_layers):\n",
        "        y = BatchNormalization()(x)\n",
        "        y = Activation('relu')(y)\n",
        "        y = Conv2D(4*growth_rate,\n",
        "                   kernel_size=1,\n",
        "                   padding='same',\n",
        "                   kernel_initializer='he_normal')(y)\n",
        "        if not data_agumentation:\n",
        "            y = Dropout(0.2)(y)\n",
        "        y = BatchNormalization()(y)\n",
        "        y = Activation('relu')(y)\n",
        "        y = Conv2D(growth_rate,\n",
        "                   kernel_size=3,\n",
        "                   padding='same',\n",
        "                   kernel_initializer='he_normal')(y)\n",
        "        if not data_agumentation:\n",
        "            y = Dropout(0.2)(y)\n",
        "        \n",
        "        x = concatenate([x,y])\n",
        "        \n",
        "    if i == num_dense_block - 1:\n",
        "        continue\n",
        "\n",
        "    num_filters_bef_dense_block += num_bottleneck_layers * growth_rate\n",
        "    num_filters_bef_dense_block = int(num_filters_bef_dense_block * compression_factor)\n",
        "    \n",
        "    y = BatchNormalization()(x)\n",
        "    y = Conv2D(num_filters_bef_dense_block,\n",
        "               kernel_size=1,\n",
        "               padding='same',\n",
        "               kernel_initializer='he_normal')(y)\n",
        "    if not data_agumentation:\n",
        "        y = Dropout(0.2)(y)\n",
        "    x = AveragePooling2D()(y)\n",
        "\n",
        "x = AveragePooling2D()(x)\n",
        "y = Flatten()(x)\n",
        "outputs = Dense(num_classes,\n",
        "                kernel_initializer='he_normal',\n",
        "                activation='softmax')(y)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "plot_model(model, show_shapes=True)\n",
        "\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_densenet_model.{epoch:02d}.h5'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_scheduler, lr_reducer]\n",
        "\n",
        "# run training, with or without data augmentation\n",
        "if not data_agumentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # preprocessing  and realtime data augmentation\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (deg 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally\n",
        "        height_shift_range=0.1,  # randomly shift images vertically\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied)\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow()\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)\n",
        "\n",
        "# score trained model\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 32, 32, 3)    12          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 32, 32, 3)    0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 32, 32, 24)   672         activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 32, 32, 27)   0           input_3[0][0]                    \n",
            "                                                                 conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 32, 32, 27)   108         concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 32, 32, 27)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 32, 32, 48)   1344        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 32, 32, 48)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 32, 32, 48)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 32, 32, 12)   5196        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 32, 32, 39)   0           concatenate_51[0][0]             \n",
            "                                                                 conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 32, 32, 39)   156         concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 32, 32, 39)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 32, 32, 48)   1920        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 48)   192         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 32, 32, 48)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 32, 32, 12)   5196        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 32, 32, 51)   0           concatenate_52[0][0]             \n",
            "                                                                 conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 32, 32, 51)   204         concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 32, 32, 51)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 32, 32, 48)   2496        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 32, 32, 48)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 32, 32, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 32, 32, 12)   5196        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 32, 32, 63)   0           concatenate_53[0][0]             \n",
            "                                                                 conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 32, 32, 63)   252         concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 32, 32, 63)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 32, 32, 48)   3072        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 32, 32, 48)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 32, 32, 48)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 32, 32, 12)   5196        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 32, 32, 75)   0           concatenate_54[0][0]             \n",
            "                                                                 conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 32, 32, 75)   300         concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 32, 32, 75)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 32, 32, 48)   3648        activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 32, 32, 48)   192         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 32, 32, 48)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 32, 32, 12)   5196        activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 32, 32, 87)   0           concatenate_55[0][0]             \n",
            "                                                                 conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 32, 32, 87)   348         concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 32, 32, 87)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 32, 32, 48)   4224        activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 32, 32, 48)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 32, 32, 48)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 32, 32, 12)   5196        activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 32, 32, 99)   0           concatenate_56[0][0]             \n",
            "                                                                 conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 32, 32, 99)   396         concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 32, 32, 99)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 32, 32, 48)   4800        activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 32, 32, 48)   192         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 32, 32, 48)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 12)   5196        activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 32, 32, 111)  0           concatenate_57[0][0]             \n",
            "                                                                 conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 32, 32, 111)  444         concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 32, 32, 111)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 32, 32, 48)   5376        activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 32, 32, 48)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 32, 32, 48)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 32, 32, 12)   5196        activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_59 (Concatenate)    (None, 32, 32, 123)  0           concatenate_58[0][0]             \n",
            "                                                                 conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 32, 32, 123)  492         concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 32, 32, 123)  0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 32, 32, 48)   5952        activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 32, 32, 48)   192         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 32, 32, 48)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 32, 32, 12)   5196        activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 32, 32, 135)  0           concatenate_59[0][0]             \n",
            "                                                                 conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 32, 32, 135)  540         concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 32, 32, 135)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 32, 32, 48)   6528        activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 32, 32, 48)   192         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 32, 32, 48)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 32, 32, 12)   5196        activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 32, 32, 147)  0           concatenate_60[0][0]             \n",
            "                                                                 conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 32, 32, 147)  588         concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 32, 32, 147)  0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 32, 32, 48)   7104        activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 32, 32, 48)   192         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 32, 32, 48)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 32, 32, 12)   5196        activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 32, 32, 159)  0           concatenate_61[0][0]             \n",
            "                                                                 conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 32, 32, 159)  636         concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 32, 32, 159)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 32, 32, 48)   7680        activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 32, 32, 48)   192         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 32, 32, 48)   0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 32, 32, 12)   5196        activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_63 (Concatenate)    (None, 32, 32, 171)  0           concatenate_62[0][0]             \n",
            "                                                                 conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 32, 32, 171)  684         concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 32, 32, 171)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 32, 32, 48)   8256        activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 32, 32, 48)   192         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 32, 32, 48)   0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 32, 32, 12)   5196        activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_64 (Concatenate)    (None, 32, 32, 183)  0           concatenate_63[0][0]             \n",
            "                                                                 conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 32, 32, 183)  732         concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 32, 32, 183)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 32, 32, 48)   8832        activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 32, 32, 48)   192         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 32, 32, 48)   0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 32, 32, 12)   5196        activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_65 (Concatenate)    (None, 32, 32, 195)  0           concatenate_64[0][0]             \n",
            "                                                                 conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 32, 32, 195)  780         concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 32, 32, 195)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 32, 32, 48)   9408        activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 32, 32, 48)   192         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 32, 32, 48)   0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 32, 32, 12)   5196        activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 32, 32, 207)  0           concatenate_65[0][0]             \n",
            "                                                                 conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 32, 32, 207)  828         concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 32, 32, 207)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 32, 32, 48)   9984        activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 32, 32, 48)   192         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 32, 32, 48)   0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 32, 32, 12)   5196        activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 32, 32, 219)  0           concatenate_66[0][0]             \n",
            "                                                                 conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 32, 32, 219)  876         concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 32, 32, 108)  23760       batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 16, 16, 108)  0           conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 16, 16, 108)  432         average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 16, 16, 108)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 16, 16, 48)   5232        activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 16, 16, 48)   192         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 16, 16, 48)   0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 16, 16, 12)   5196        activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_68 (Concatenate)    (None, 16, 16, 120)  0           average_pooling2d_4[0][0]        \n",
            "                                                                 conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 16, 16, 120)  480         concatenate_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 16, 16, 120)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 16, 16, 48)   5808        activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 16, 16, 48)   192         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 16, 16, 48)   0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 16, 16, 12)   5196        activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_69 (Concatenate)    (None, 16, 16, 132)  0           concatenate_68[0][0]             \n",
            "                                                                 conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 16, 16, 132)  528         concatenate_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 16, 16, 132)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 16, 16, 48)   6384        activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 16, 16, 48)   192         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 16, 16, 48)   0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 16, 16, 12)   5196        activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_70 (Concatenate)    (None, 16, 16, 144)  0           concatenate_69[0][0]             \n",
            "                                                                 conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 16, 16, 144)  576         concatenate_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 16, 16, 144)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 16, 16, 48)   6960        activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 16, 16, 48)   192         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 16, 16, 48)   0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 16, 16, 12)   5196        activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_71 (Concatenate)    (None, 16, 16, 156)  0           concatenate_70[0][0]             \n",
            "                                                                 conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 16, 16, 156)  624         concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 16, 16, 156)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 16, 16, 48)   7536        activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 16, 16, 48)   192         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 16, 16, 48)   0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 16, 16, 12)   5196        activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_72 (Concatenate)    (None, 16, 16, 168)  0           concatenate_71[0][0]             \n",
            "                                                                 conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 16, 16, 168)  672         concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 16, 16, 168)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 16, 16, 48)   8112        activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 16, 16, 48)   192         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 16, 16, 48)   0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 16, 16, 12)   5196        activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_73 (Concatenate)    (None, 16, 16, 180)  0           concatenate_72[0][0]             \n",
            "                                                                 conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 16, 16, 180)  720         concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 16, 16, 180)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 16, 16, 48)   8688        activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 16, 16, 48)   192         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 16, 16, 48)   0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 16, 16, 12)   5196        activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_74 (Concatenate)    (None, 16, 16, 192)  0           concatenate_73[0][0]             \n",
            "                                                                 conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 16, 16, 192)  768         concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 16, 16, 192)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 16, 16, 48)   9264        activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 16, 16, 48)   192         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 16, 16, 48)   0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 16, 16, 12)   5196        activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_75 (Concatenate)    (None, 16, 16, 204)  0           concatenate_74[0][0]             \n",
            "                                                                 conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 16, 16, 204)  816         concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 16, 16, 204)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 16, 16, 48)   9840        activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 16, 16, 48)   192         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 16, 16, 48)   0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 16, 16, 12)   5196        activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_76 (Concatenate)    (None, 16, 16, 216)  0           concatenate_75[0][0]             \n",
            "                                                                 conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 16, 16, 216)  864         concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 16, 16, 216)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 16, 16, 48)   10416       activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 16, 16, 48)   192         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 16, 16, 48)   0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 16, 16, 12)   5196        activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_77 (Concatenate)    (None, 16, 16, 228)  0           concatenate_76[0][0]             \n",
            "                                                                 conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 16, 16, 228)  912         concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 16, 16, 228)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 16, 16, 48)   10992       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 16, 16, 48)   192         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 16, 16, 48)   0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 16, 16, 12)   5196        activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 16, 16, 240)  0           concatenate_77[0][0]             \n",
            "                                                                 conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 16, 16, 240)  960         concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 16, 16, 240)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 16, 16, 48)   11568       activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 16, 16, 48)   192         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 16, 16, 48)   0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 16, 16, 12)   5196        activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_79 (Concatenate)    (None, 16, 16, 252)  0           concatenate_78[0][0]             \n",
            "                                                                 conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 16, 16, 252)  1008        concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 16, 16, 252)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 16, 16, 48)   12144       activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 16, 16, 48)   192         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 16, 16, 48)   0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 16, 16, 12)   5196        activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_80 (Concatenate)    (None, 16, 16, 264)  0           concatenate_79[0][0]             \n",
            "                                                                 conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 16, 16, 264)  1056        concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 16, 16, 264)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 16, 16, 48)   12720       activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 16, 16, 48)   192         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 16, 16, 48)   0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 16, 16, 12)   5196        activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_81 (Concatenate)    (None, 16, 16, 276)  0           concatenate_80[0][0]             \n",
            "                                                                 conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 16, 16, 276)  1104        concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 16, 16, 276)  0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 16, 16, 48)   13296       activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 16, 16, 48)   192         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 16, 16, 48)   0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 16, 16, 12)   5196        activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_82 (Concatenate)    (None, 16, 16, 288)  0           concatenate_81[0][0]             \n",
            "                                                                 conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 16, 16, 288)  1152        concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 16, 16, 288)  0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 16, 16, 48)   13872       activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 16, 16, 48)   192         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 16, 16, 48)   0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 16, 16, 12)   5196        activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_83 (Concatenate)    (None, 16, 16, 300)  0           concatenate_82[0][0]             \n",
            "                                                                 conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 16, 16, 300)  1200        concatenate_83[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 16, 16, 150)  45150       batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 8, 8, 150)    0           conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 8, 8, 150)    600         average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 8, 8, 150)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 8, 8, 48)     7248        activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 8, 8, 48)     192         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 8, 8, 48)     0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 8, 8, 12)     5196        activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_84 (Concatenate)    (None, 8, 8, 162)    0           average_pooling2d_5[0][0]        \n",
            "                                                                 conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 8, 8, 162)    648         concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 8, 8, 162)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 8, 8, 48)     7824        activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 8, 8, 48)     192         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 8, 8, 48)     0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 8, 8, 12)     5196        activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_85 (Concatenate)    (None, 8, 8, 174)    0           concatenate_84[0][0]             \n",
            "                                                                 conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 8, 8, 174)    696         concatenate_85[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 8, 8, 174)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 8, 8, 48)     8400        activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 8, 8, 48)     192         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 8, 8, 48)     0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 8, 8, 12)     5196        activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_86 (Concatenate)    (None, 8, 8, 186)    0           concatenate_85[0][0]             \n",
            "                                                                 conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 8, 8, 186)    744         concatenate_86[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 8, 8, 186)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 48)     8976        activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 8, 8, 48)     192         conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 8, 8, 48)     0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 8, 8, 12)     5196        activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_87 (Concatenate)    (None, 8, 8, 198)    0           concatenate_86[0][0]             \n",
            "                                                                 conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 8, 8, 198)    792         concatenate_87[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 8, 8, 198)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 48)     9552        activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 8, 8, 48)     192         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 8, 8, 48)     0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 8, 8, 12)     5196        activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_88 (Concatenate)    (None, 8, 8, 210)    0           concatenate_87[0][0]             \n",
            "                                                                 conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 8, 8, 210)    840         concatenate_88[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 8, 8, 210)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 8, 8, 48)     10128       activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 8, 8, 48)     192         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 8, 8, 48)     0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 8, 8, 12)     5196        activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_89 (Concatenate)    (None, 8, 8, 222)    0           concatenate_88[0][0]             \n",
            "                                                                 conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 8, 8, 222)    888         concatenate_89[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 8, 8, 222)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 8, 8, 48)     10704       activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 8, 8, 48)     192         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 8, 8, 48)     0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 8, 8, 12)     5196        activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_90 (Concatenate)    (None, 8, 8, 234)    0           concatenate_89[0][0]             \n",
            "                                                                 conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 8, 8, 234)    936         concatenate_90[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 8, 8, 234)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 8, 8, 48)     11280       activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 8, 8, 48)     192         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 8, 8, 48)     0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 8, 8, 12)     5196        activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_91 (Concatenate)    (None, 8, 8, 246)    0           concatenate_90[0][0]             \n",
            "                                                                 conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 8, 8, 246)    984         concatenate_91[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 8, 8, 246)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 8, 8, 48)     11856       activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 8, 8, 48)     192         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 8, 8, 48)     0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 8, 8, 12)     5196        activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_92 (Concatenate)    (None, 8, 8, 258)    0           concatenate_91[0][0]             \n",
            "                                                                 conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 8, 8, 258)    1032        concatenate_92[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 8, 8, 258)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 8, 8, 48)     12432       activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 8, 8, 48)     192         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 8, 8, 48)     0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 8, 8, 12)     5196        activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_93 (Concatenate)    (None, 8, 8, 270)    0           concatenate_92[0][0]             \n",
            "                                                                 conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 8, 8, 270)    1080        concatenate_93[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 270)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 8, 8, 48)     13008       activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 8, 8, 48)     192         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 8, 48)     0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 8, 8, 12)     5196        activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_94 (Concatenate)    (None, 8, 8, 282)    0           concatenate_93[0][0]             \n",
            "                                                                 conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 8, 8, 282)    1128        concatenate_94[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 8, 282)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 8, 8, 48)     13584       activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 8, 8, 48)     192         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 8, 8, 48)     0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 8, 8, 12)     5196        activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_95 (Concatenate)    (None, 8, 8, 294)    0           concatenate_94[0][0]             \n",
            "                                                                 conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 8, 8, 294)    1176        concatenate_95[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 8, 8, 294)    0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 8, 8, 48)     14160       activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 8, 8, 48)     192         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 8, 8, 48)     0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 8, 8, 12)     5196        activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_96 (Concatenate)    (None, 8, 8, 306)    0           concatenate_95[0][0]             \n",
            "                                                                 conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 8, 8, 306)    1224        concatenate_96[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 8, 8, 306)    0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 8, 8, 48)     14736       activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 8, 8, 48)     192         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 8, 8, 48)     0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 8, 8, 12)     5196        activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_97 (Concatenate)    (None, 8, 8, 318)    0           concatenate_96[0][0]             \n",
            "                                                                 conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 8, 8, 318)    1272        concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 8, 8, 318)    0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 8, 8, 48)     15312       activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 8, 8, 48)     192         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 8, 8, 48)     0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 8, 8, 12)     5196        activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_98 (Concatenate)    (None, 8, 8, 330)    0           concatenate_97[0][0]             \n",
            "                                                                 conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 8, 8, 330)    1320        concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 8, 8, 330)    0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 8, 8, 48)     15888       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 8, 8, 48)     192         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 8, 8, 48)     0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 8, 8, 12)     5196        activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_99 (Concatenate)    (None, 8, 8, 342)    0           concatenate_98[0][0]             \n",
            "                                                                 conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 4, 4, 342)    0           concatenate_99[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 5472)         0           average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           54730       flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 849,088\n",
            "Trainable params: 825,676\n",
            "Non-trainable params: 23,412\n",
            "__________________________________________________________________________________________________\n",
            "Using real-time data augmentation.\n",
            "Epoch 1/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 268s 171ms/step - loss: 1.6701 - acc: 0.4433 - val_loss: 1.2804 - val_acc: 0.5682\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.56820, saving model to /content/saved_models/cifar10_densenet_model.01.h5\n",
            "Epoch 2/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 244s 156ms/step - loss: 1.1642 - acc: 0.5958 - val_loss: 1.2621 - val_acc: 0.5783\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.56820 to 0.57830, saving model to /content/saved_models/cifar10_densenet_model.02.h5\n",
            "Epoch 3/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 246s 157ms/step - loss: 0.9621 - acc: 0.6673 - val_loss: 0.9655 - val_acc: 0.6610\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.57830 to 0.66100, saving model to /content/saved_models/cifar10_densenet_model.03.h5\n",
            "Epoch 4/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 246s 157ms/step - loss: 0.8379 - acc: 0.7088 - val_loss: 0.9462 - val_acc: 0.7021\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.66100 to 0.70210, saving model to /content/saved_models/cifar10_densenet_model.04.h5\n",
            "Epoch 5/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 247s 158ms/step - loss: 0.7569 - acc: 0.7422 - val_loss: 0.8219 - val_acc: 0.7298\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.70210 to 0.72980, saving model to /content/saved_models/cifar10_densenet_model.05.h5\n",
            "Epoch 6/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 246s 158ms/step - loss: 0.6889 - acc: 0.7663 - val_loss: 0.9429 - val_acc: 0.6920\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.72980\n",
            "Epoch 7/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 246s 157ms/step - loss: 0.6406 - acc: 0.7818 - val_loss: 0.8943 - val_acc: 0.7209\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.72980\n",
            "Epoch 8/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 247s 158ms/step - loss: 0.5972 - acc: 0.7977 - val_loss: 0.8221 - val_acc: 0.7570\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.72980 to 0.75700, saving model to /content/saved_models/cifar10_densenet_model.08.h5\n",
            "Epoch 9/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 248s 159ms/step - loss: 0.5691 - acc: 0.8056 - val_loss: 0.9378 - val_acc: 0.7394\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.75700\n",
            "Epoch 10/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 244s 156ms/step - loss: 0.5422 - acc: 0.8168 - val_loss: 0.7625 - val_acc: 0.7693\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.75700 to 0.76930, saving model to /content/saved_models/cifar10_densenet_model.10.h5\n",
            "Epoch 11/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 243s 156ms/step - loss: 0.5163 - acc: 0.8268 - val_loss: 0.7138 - val_acc: 0.7837\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.76930 to 0.78370, saving model to /content/saved_models/cifar10_densenet_model.11.h5\n",
            "Epoch 12/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 242s 155ms/step - loss: 0.4918 - acc: 0.8328 - val_loss: 0.6639 - val_acc: 0.7920\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.78370 to 0.79200, saving model to /content/saved_models/cifar10_densenet_model.12.h5\n",
            "Epoch 13/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 240s 154ms/step - loss: 0.4751 - acc: 0.8396 - val_loss: 0.6244 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.79200 to 0.81330, saving model to /content/saved_models/cifar10_densenet_model.13.h5\n",
            "Epoch 14/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 241s 154ms/step - loss: 0.4576 - acc: 0.8459 - val_loss: 0.8271 - val_acc: 0.7640\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.81330\n",
            "Epoch 15/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 241s 154ms/step - loss: 0.4499 - acc: 0.8506 - val_loss: 0.5916 - val_acc: 0.8226\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.81330 to 0.82260, saving model to /content/saved_models/cifar10_densenet_model.15.h5\n",
            "Epoch 16/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 241s 154ms/step - loss: 0.4358 - acc: 0.8561 - val_loss: 0.5524 - val_acc: 0.8267\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.82260 to 0.82670, saving model to /content/saved_models/cifar10_densenet_model.16.h5\n",
            "Epoch 17/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 240s 154ms/step - loss: 0.4274 - acc: 0.8597 - val_loss: 0.6283 - val_acc: 0.8199\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.82670\n",
            "Epoch 18/100\n",
            "Learning rate:  0.001\n",
            "1562/1562 [==============================] - 240s 153ms/step - loss: 0.4211 - acc: 0.8629 - val_loss: 0.5555 - val_acc: 0.8327\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.82670 to 0.83270, saving model to /content/saved_models/cifar10_densenet_model.18.h5\n",
            "Epoch 19/100\n",
            "Learning rate:  0.001\n",
            "1090/1562 [===================>..........] - ETA: 1:09 - loss: 0.4011 - acc: 0.8665"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Th_Zmx15sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}